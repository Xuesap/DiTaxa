{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from utility.file_utility import FileUtility\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cv_res(filename):\n",
    "    [label_set, conf, best_score_, best_estimator_,cv_results_, best_params_, pred]=FileUtility.load_obj(filename)\n",
    "    res=dict()\n",
    "    idx=np.argmax(cv_results_['mean_test_f1_macro'])\n",
    "    res['f1_macro*']=np.round(cv_results_['mean_test_f1_macro'][idx],2)\n",
    "    res['f1_macro']=str(np.round(cv_results_['mean_test_f1_macro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_f1_macro'][idx],2))\n",
    "    res['f1_micro']=str(np.round(cv_results_['mean_test_f1_micro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_f1_micro'][idx],2))\n",
    "    res['precision_micro']=str(np.round(cv_results_['mean_test_precision_micro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_precision_micro'][idx],2))\n",
    "    res['precision_macro']=str(np.round(cv_results_['mean_test_precision_macro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_precision_macro'][idx],2))\n",
    "    res['recall_micro']=str(np.round(cv_results_['mean_test_recall_micro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_recall_micro'][idx],2))\n",
    "    res['recall_macro']=str(np.round(cv_results_['mean_test_recall_macro'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_recall_macro'][idx],2))\n",
    "    res['accuracy']=str(np.round(cv_results_['mean_test_accuracy'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_accuracy'][idx],2))\n",
    "    res['tnr']=str(np.round(cv_results_['mean_test_tnr'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_tnr'][idx],2))\n",
    "    res['scores_p_0']=str(np.round(cv_results_['mean_test_scores_p_0'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_p_0'][idx],2))\n",
    "    res['scores_r_0']=str(np.round(cv_results_['mean_test_scores_r_0'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_r_0'][idx],2))\n",
    "    res['scores_f_1_0']=str(np.round(cv_results_['mean_test_scores_f_1_0'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_f_1_0'][idx],2))\n",
    "    res['scores_f_1_1']=str(np.round(cv_results_['mean_test_scores_f_1_1'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_f_1_1'][idx],2))\n",
    "    res['scores_p_1']=str(np.round(cv_results_['mean_test_scores_p_1'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_p_1'][idx],2))\n",
    "    res['scores_r_1']=str(np.round(cv_results_['mean_test_scores_r_1'][idx],2))+ ' $\\pm$ ' + str(np.round(cv_results_['std_test_scores_r_1'][idx],2)) \n",
    "    res['file']=filename\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mounts/data/proj/asgari/dissertation/git_repos/16S_datasets/synthetic/res_other/syn_6-mers_5000_RF_RF.pickle',\n",
       " '/mounts/data/proj/asgari/dissertation/git_repos/16S_datasets/synthetic/res_other/otu_RF.pickle']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_table_from_files(files):\n",
    "    table = {'dataset': [], 'vocab': [], 'sample_size':[],'f1_macro':[],'f1_micro':[],'precision_micro':[],'precision_macro':[],'recall_micro':[],'recall_macro':[],'accuracy':[],'tnr':[],'scores_p_0':[],'scores_r_0':[],'scores_f_1_0':[],'scores_p_1':[],'scores_r_1':[],'scores_f_1_1':[]}\n",
    "    for file in files:        \n",
    "        ds__vocab__sample=file.split('/')[-1].replace('.pickle','').split('_')\n",
    "        res=get_cv_res(file)\n",
    "        for key in table:\n",
    "            if key=='dataset':\n",
    "                table['dataset'].append(ds__vocab__sample[0])\n",
    "            elif key=='vocab':\n",
    "                table['vocab'].append(int(ds__vocab__sample[2]))\n",
    "            elif key=='sample_size':\n",
    "                table['sample_size'].append(ds__vocab__sample[4])\n",
    "            else:\n",
    "                table[key].append(res[key])\n",
    "    df=pd.DataFrame(data=table,columns=['dataset', 'vocab','sample_size','precision_micro','recall_micro','f1_micro','precision_macro','recall_macro','f1_macro'])\n",
    "    df = df.set_index('dataset', append=True).swaplevel(0,1)\n",
    "    df.sort_values(by=['vocab'])\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrlllllll}\n",
      "\\toprule\n",
      "   &   &  vocab & sample\\_size & precision\\_micro &    recall\\_micro &        f1\\_micro &  precision\\_macro &     recall\\_macro &         f1\\_macro \\\\\n",
      "dataset & {} &        &             &                 &                 &                 &                  &                  &                  \\\\\n",
      "\\midrule\n",
      "ra & 0 &   5000 &          RF &  0.78 $\\pm$ 0.1 &  0.78 $\\pm$ 0.1 &  0.78 $\\pm$ 0.1 &  0.78 $\\pm$ 0.12 &  0.76 $\\pm$ 0.12 &  0.76 $\\pm$ 0.12 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path2res='/mounts/data/proj/asgari/dissertation/git_repos/16S_datasets/ra/reskmer/'\n",
    "files=FileUtility.recursive_glob(path2res,'*.pickle')\n",
    "print (get_table_from_files(files).to_latex().replace('\\\\$\\\\textbackslashpm\\\\$','$\\pm$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrlllllll}\n",
      "\\toprule\n",
      "    &   &  vocab & sample\\_size & precision\\_micro &   recall\\_micro &       f1\\_micro & precision\\_macro &   recall\\_macro &       f1\\_macro \\\\\n",
      "dataset & {} &        &             &                 &                &                &                 &                &                \\\\\n",
      "\\midrule\n",
      "syn & 0 &   1041 &          RF &   1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 &   1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 \\\\\n",
      "    & 1 &   5000 &          RF &   1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 &   1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 &  1.0 $\\pm$ 0.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path2res='/mounts/data/proj/asgari/dissertation/git_repos/16S_datasets/synthetic/res_other/'\n",
    "files=FileUtility.recursive_glob(path2res,'*.pickle')\n",
    "get_table_from_files(files)\n",
    "print (get_table_from_files(files).to_latex().replace('\\\\$\\\\textbackslashpm\\\\$','$\\pm$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrlllllll}\n",
      "\\toprule\n",
      "       &   &  vocab & sample\\_size &  precision\\_micro &     recall\\_micro &         f1\\_micro &  precision\\_macro &     recall\\_macro &         f1\\_macro \\\\\n",
      "dataset & {} &        &             &                  &                  &                  &                  &                  &                  \\\\\n",
      "\\midrule\n",
      "crohns & 0 &  20000 &       10000 &  0.75 $\\pm$ 0.04 &  0.75 $\\pm$ 0.04 &  0.75 $\\pm$ 0.04 &  0.75 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 \\\\\n",
      "       & 1 &  50000 &          -1 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 \\\\\n",
      "       & 2 &  10000 &        5000 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.74 $\\pm$ 0.04 &  0.73 $\\pm$ 0.04 &  0.73 $\\pm$ 0.04 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path2res='/mounts/data/proj/asgari/dissertation/git_repos/16S_datasets/crohns/res/'\n",
    "files=FileUtility.recursive_glob(path2res,'*.pickle')\n",
    "get_table_from_files(files)\n",
    "print (get_table_from_files(files).to_latex().replace('\\\\$\\\\textbackslashpm\\\\$','$\\pm$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
